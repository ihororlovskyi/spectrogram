"""
Audio Spectrogram Web Service
–í–µ–±-—Å–µ—Ä–≤—ñ—Å –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –∞—É–¥—ñ–æ—Ñ–∞–π–ª—ñ–≤ –∑ GPU-–ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è–º
–ì–µ–Ω–µ—Ä—É—î 2D —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏
"""

import os
import asyncio
from pathlib import Path
from typing import Optional
import numpy as np
from fastapi import FastAPI, UploadFile, File, HTTPException, BackgroundTasks
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, HTMLResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import librosa
import librosa.display
import matplotlib
matplotlib.use('Agg')  # –î–ª—è —Å–µ—Ä–≤–µ—Ä–Ω–æ–≥–æ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥—É
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import soundfile as sf
from PIL import Image, ImageEnhance
from pydantic import BaseModel
from datetime import datetime, timedelta
import shutil
import time
import hashlib

# –°–ø—Ä–æ–±–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ CuPy –¥–ª—è GPU –æ–±—Ä–æ–±–∫–∏
try:
    import cupy as cp
    GPU_AVAILABLE = True
    print("‚úì GPU (CuPy) –¥–æ—Å—Ç—É–ø–Ω–∏–π –¥–ª—è –æ–±—Ä–æ–±–∫–∏")
except ImportError:
    cp = np
    GPU_AVAILABLE = False
    print("‚úó GPU –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è CPU (NumPy)")

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–æ–¥–∞—Ç–∫—É
app = FastAPI(
    title="Audio Spectrogram Service",
    description="–í–µ–±-—Å–µ—Ä–≤—ñ—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó 2D —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º –∑ GPU-–ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è–º",
    version="1.0.0"
)

# CORS –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥—É
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
BASE_DIR = Path(__file__).parent
UPLOAD_DIR = BASE_DIR / "uploads"
OUTPUT_DIR = BASE_DIR / "outputs"
STATIC_DIR = BASE_DIR / "static"

UPLOAD_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)
STATIC_DIR.mkdir(exist_ok=True)

# –°—Ç–∞—Ç–∏—á–Ω—ñ —Ñ–∞–π–ª–∏
app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")
app.mount("/outputs", StaticFiles(directory=str(OUTPUT_DIR)), name="outputs")

# –ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ —Ñ–æ—Ä–º–∞—Ç–∏
SUPPORTED_FORMATS = {'.mp3', '.wav', '.flac', '.ogg', '.m4a', '.aac', '.wma'}
MAX_FILE_SIZE = 100 * 1024 * 1024  # 100 MB

# –ó–±–µ—Ä—ñ–≥–∞–Ω–Ω—è —Å—Ç–∞—Ç—É—Å—ñ–≤ –∑–∞–≤–¥–∞–Ω—å
tasks_status = {}


class TaskStatus(BaseModel):
    task_id: str
    status: str  # pending, processing, completed, error
    progress: int
    message: str
    result: Optional[dict] = None


def validate_audio_file(filename: str) -> bool:
    """–í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ñ–æ—Ä–º–∞—Ç—É –∞—É–¥—ñ–æ—Ñ–∞–π–ª—É"""
    ext = Path(filename).suffix.lower()
    return ext in SUPPORTED_FORMATS


def generate_task_id() -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —É–Ω—ñ–∫–∞–ª—å–Ω–æ–≥–æ ID –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ç–∞–π–º—Å—Ç–µ–º–ø—É"""
    return str(int(time.time() * 1000))


def generate_preview_hash(colormap: str, scale: str, fft_size: int, mode: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ö–µ—à—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –ø—Ä–µ–≤ º—é"""
    params = f"{colormap}_{scale}_{fft_size}_{mode}"
    return hashlib.md5(params.encode()).hexdigest()[:8]


def compute_spectrogram_gpu(audio: np.ndarray, sr: int, n_fft: int = 2048,
                            hop_length: int = 512, use_gpu: bool = True) -> np.ndarray:
    """
    –û–±—á–∏—Å–ª–µ–Ω–Ω—è —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º GPU (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∏–π)
    use_gpu: —è–∫—â–æ True - –Ω–∞–º–∞–≥–∞—î–º–æ—Å—å –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ GPU, —è–∫—â–æ False - –∑–∞–≤–∂–¥–∏ CPU
    """
    if GPU_AVAILABLE and use_gpu:
        # –ü–µ—Ä–µ–Ω–æ—Å–∏–º–æ –¥–∞–Ω—ñ –Ω–∞ GPU
        audio_gpu = cp.asarray(audio)

        # STFT –Ω–∞ GPU
        n_frames = 1 + (len(audio_gpu) - n_fft) // hop_length
        stft_matrix = cp.zeros((n_fft // 2 + 1, n_frames), dtype=cp.complex64)

        window = cp.hanning(n_fft).astype(cp.float32)

        for i in range(n_frames):
            start = i * hop_length
            frame = audio_gpu[start:start + n_fft]
            if len(frame) < n_fft:
                frame = cp.pad(frame, (0, n_fft - len(frame)))
            windowed = frame * window
            spectrum = cp.fft.rfft(windowed)
            stft_matrix[:, i] = spectrum

        # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è —É –¥–µ—Ü–∏–±–µ–ª–∏
        magnitude = cp.abs(stft_matrix)
        spectrogram_db = 20 * cp.log10(cp.maximum(magnitude, 1e-10))

        # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –Ω–∞ CPU
        return cp.asnumpy(spectrogram_db)
    else:
        # CPU fallback –∑ librosa
        stft = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length)
        spectrogram_db = librosa.amplitude_to_db(np.abs(stft), ref=np.max)
        return spectrogram_db


def enhance_image(image_path: str, mode: str = "classic"):
    """
    –ü–æ—Å–∏–ª–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫–∏
    mode: "classic" - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è, "sharp" - –ø–æ—Å–∏–ª–µ–Ω–µ, "sharper" - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ—Å–∏–ª–µ–Ω–µ
    """
    if mode == "classic":
        return

    try:
        img = Image.open(image_path)

        if mode == "sharp":
            # –ü–æ—Å–∏–ª–µ–Ω–Ω—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—ñ
            enhancer_contrast = ImageEnhance.Contrast(img)
            img = enhancer_contrast.enhance(1.3)

            # –ü–æ—Å–∏–ª–µ–Ω–Ω—è –Ω–∞—Å–∏—á–µ–Ω–æ—Å—Ç—ñ
            enhancer_color = ImageEnhance.Color(img)
            img = enhancer_color.enhance(1.2)

            # –õ–µ–≥–∫–µ –ø–æ—Å–∏–ª–µ–Ω–Ω—è —Ä—ñ–∑–∫–æ—Å—Ç—ñ
            enhancer_sharpness = ImageEnhance.Sharpness(img)
            img = enhancer_sharpness.enhance(1.5)

        elif mode == "sharper":
            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–µ –ø–æ—Å–∏–ª–µ–Ω–Ω—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—ñ
            enhancer_contrast = ImageEnhance.Contrast(img)
            img = enhancer_contrast.enhance(1.6)

            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–µ –ø–æ—Å–∏–ª–µ–Ω–Ω—è –Ω–∞—Å–∏—á–µ–Ω–æ—Å—Ç—ñ
            enhancer_color = ImageEnhance.Color(img)
            img = enhancer_color.enhance(1.5)

            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–µ –ø–æ—Å–∏–ª–µ–Ω–Ω—è —Ä—ñ–∑–∫–æ—Å—Ç—ñ
            enhancer_sharpness = ImageEnhance.Sharpness(img)
            img = enhancer_sharpness.enhance(2.0)

            # –ü–æ—Å–∏–ª–µ–Ω–Ω—è —è—Å–∫—Ä–∞–≤–æ—Å—Ç—ñ
            enhancer_brightness = ImageEnhance.Brightness(img)
            img = enhancer_brightness.enhance(1.1)

        img.save(image_path, quality=95, optimize=False)
    except Exception as e:
        print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ—Å–∏–ª–µ–Ω–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {e}")


def generate_2d_spectrogram(audio_path: str, output_path: str,
                            colormap: str = "magma", scale: str = "linear", n_fft: int = 2048,
                            mode: str = "classic", use_gpu: bool = True) -> dict:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è 2D —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —è–∫ PNG
    scale: "linear", "log", "mel"
    n_fft: FFT size (256, 512, 1024, 2048, 4096, 8192, 16384)
    mode: "classic", "sharp", "sharper" - –¥–∏–Ω–∞–º—ñ—á–Ω–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω
    use_gpu: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ GPU –æ–±—Ä–æ–±–∫—É —è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∞
    """
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ
    audio, sr = librosa.load(audio_path, sr=None, mono=True)
    duration = librosa.get_duration(y=audio, sr=sr)

    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏
    hop_length = n_fft // 4
    spectrogram_db = compute_spectrogram_gpu(audio, sr, n_fft, hop_length, use_gpu)

    # –ö–æ–Ω—Ç—Ä–æ–ª—å –¥–∏–Ω–∞–º—ñ—á–Ω–æ–≥–æ –¥—ñ–∞–ø–∞–∑–æ–Ω—É –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ Mode
    mode_top_db = {
        "classic": None,    # –í—Å—è —à–∫–∞–ª–∞ - –Ω–µ –æ–±—Ä—ñ–∑–∞—î–º–æ
        "sharp": 80,        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω
        "sharper": 50       # –í—É–∑—å–∫–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—ñ
    }
    top_db = mode_top_db.get(mode, None)

    # –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è top_db –¥–ª—è –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó
    if top_db is not None:
        spectrogram_db = np.maximum(spectrogram_db, spectrogram_db.max() - top_db)

    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó (4K resolution: 3840x2160)
    fig, ax = plt.subplots(figsize=(22.8, 12.8), dpi=168)

    # –ö–∞—Å—Ç–æ–º–Ω–∞ –∫–æ–ª—å–æ—Ä–æ–≤–∞ –∫–∞—Ä—Ç–∞
    if colormap == "custom":
        colors = ['#0d0221', '#0d1b2a', '#1b263b', '#415a77',
                  '#778da9', '#e0e1dd', '#ff6b6b', '#ffd93d']
        custom_cmap = LinearSegmentedColormap.from_list("audio_spectrum", colors)
        cmap = custom_cmap
    elif colormap == "gray":
        cmap = "gray"
    else:
        cmap = colormap

    # –í–∏–±—ñ—Ä –æ—Å—ñ Y –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Ç–∏–ø—É –º–∞—Å—à—Ç–∞–±–∞
    y_axis_map = {
        "linear": "hz",
        "log": "log",
        "mel": "mel",
    }
    y_axis = y_axis_map.get(scale, "hz")

    img = librosa.display.specshow(
        spectrogram_db,
        sr=sr,
        hop_length=hop_length,
        x_axis='time',
        y_axis=y_axis,
        cmap=cmap,
        ax=ax
    )
    
    # –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è labels –æ—Å–µ–π
    y_label_map = {
        "linear": "–ß–∞—Å—Ç–æ—Ç–∞ (–ì—Ü)",
        "log": "–ß–∞—Å—Ç–æ—Ç–∞ (–ì—Ü, log)",
        "mel": "Mel-—á–∞—Å—Ç–æ—Ç–∞",
        "bark": "Bark-—á–∞—Å—Ç–æ—Ç–∞"
    }
    y_label = y_label_map.get(scale, "–ß–∞—Å—Ç–æ—Ç–∞ (–ì—Ü)")

    ax.set_xlabel('–ß–∞—Å (—Å)', fontsize=12, color='white')
    ax.set_ylabel(y_label, fontsize=12, color='white')
    ax.set_title('–°–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∞ –∞—É–¥—ñ–æ', fontsize=14, color='white', pad=10)
    
    # –°—Ç–∏–ª—ñ–∑–∞—Ü—ñ—è
    fig.patch.set_facecolor('#0d0221')
    ax.set_facecolor('#0d0221')
    ax.tick_params(colors='white')
    for spine in ax.spines.values():
        spine.set_color('#415a77')
    
    # –ö–æ–ª—å–æ—Ä–æ–≤–∞ —à–∫–∞–ª–∞
    cbar = fig.colorbar(img, ax=ax, format='%+2.0f –¥–ë')
    cbar.ax.yaxis.set_tick_params(color='white')
    cbar.outline.set_edgecolor('#415a77')
    plt.setp(plt.getp(cbar.ax.axes, 'yticklabels'), color='white')
    cbar.set_label('–Ü–Ω—Ç–µ–Ω—Å–∏–≤–Ω—ñ—Å—Ç—å (–¥–ë)', color='white')
    
    plt.tight_layout()
    plt.savefig(output_path, facecolor=fig.get_facecolor(),
                edgecolor='none', bbox_inches='tight')
    plt.close()

    # –ü–æ—Å–∏–ª–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫–∏
    enhance_image(output_path, mode)

    return {
        "duration": round(duration, 2),
        "sample_rate": sr,
        "frequency_bins": spectrogram_db.shape[0],
        "time_frames": spectrogram_db.shape[1]
    }


def generate_2d_preview(audio_path: str, output_path: str,
                       colormap: str = "magma", scale: str = "linear", n_fft: int = 2048,
                       mode: str = "classic", use_gpu: bool = True) -> dict:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –Ω–µ–≤–µ–ª–∏–∫–æ–≥–æ –ø—Ä–µ–≤ º—é —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏ (320px —à–∏—Ä–∏–Ω–∏)
    –®–≤–∏–¥—à–∞ –≤–µ—Ä—Å—ñ—è –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —á–∞—Å—É
    mode: "classic", "sharp", "sharper" - –¥–∏–Ω–∞–º—ñ—á–Ω–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω
    use_gpu: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ GPU –æ–±—Ä–æ–±–∫—É —è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∞
    """
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ
    audio, sr = librosa.load(audio_path, sr=None, mono=True)
    duration = librosa.get_duration(y=audio, sr=sr)

    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏
    hop_length = n_fft // 4
    spectrogram_db = compute_spectrogram_gpu(audio, sr, n_fft, hop_length, use_gpu)

    # –ö–æ–Ω—Ç—Ä–æ–ª—å –¥–∏–Ω–∞–º—ñ—á–Ω–æ–≥–æ –¥—ñ–∞–ø–∞–∑–æ–Ω—É –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ Mode
    mode_top_db = {
        "classic": None,    # –í—Å—è —à–∫–∞–ª–∞ - –Ω–µ –æ–±—Ä—ñ–∑–∞—î–º–æ
        "sharp": 80,        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω
        "sharper": 50       # –í—É–∑—å–∫–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—ñ
    }
    top_db = mode_top_db.get(mode, None)

    # –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è top_db –¥–ª—è –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó
    if top_db is not None:
        spectrogram_db = np.maximum(spectrogram_db, spectrogram_db.max() - top_db)

    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—Ä–µ–≤ º—é (320px —à–∏—Ä–∏–Ω–∏ = 1.8 –¥—é–π–º–∏ –ø—Ä–∏ 176 dpi)
    fig, ax = plt.subplots(figsize=(1.8, 1.012), dpi=176)

    # –ö–æ–ª—å–æ—Ä–æ–≤–∞ –∫–∞—Ä—Ç–∞
    if colormap == "custom":
        colors = ['#0d0221', '#0d1b2a', '#1b263b', '#415a77',
                  '#778da9', '#e0e1dd', '#ff6b6b', '#ffd93d']
        custom_cmap = LinearSegmentedColormap.from_list("audio_spectrum", colors)
        cmap = custom_cmap
    elif colormap == "gray":
        cmap = "gray"
    else:
        cmap = colormap

    # –í–∏–±—ñ—Ä –æ—Å—ñ Y –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Ç–∏–ø—É –º–∞—Å—à—Ç–∞–±–∞
    y_axis_map = {
        "linear": "hz",
        "log": "log",
        "mel": "mel",
    }
    y_axis = y_axis_map.get(scale, "hz")

    img = librosa.display.specshow(
        spectrogram_db,
        sr=sr,
        hop_length=hop_length,
        x_axis='time',
        y_axis=y_axis,
        cmap=cmap,
        ax=ax
    )

    ax.set_xlabel('', fontsize=6, color='white')
    ax.set_ylabel('', fontsize=6, color='white')
    ax.tick_params(labelsize=5)

    # –°—Ç–∏–ª—ñ–∑–∞—Ü—ñ—è
    fig.patch.set_facecolor('#0d0221')
    ax.set_facecolor('#0d0221')
    ax.tick_params(colors='white')
    for spine in ax.spines.values():
        spine.set_color('#415a77')

    plt.tight_layout(pad=0.1)
    plt.savefig(output_path, facecolor=fig.get_facecolor(),
                edgecolor='none', bbox_inches='tight', pad_inches=0.02)
    plt.close()

    # –ü–æ—Å–∏–ª–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫–∏
    enhance_image(output_path, mode)

    return {
        "duration": round(duration, 2),
        "sample_rate": sr,
        "frequency_bins": spectrogram_db.shape[0],
        "time_frames": spectrogram_db.shape[1]
    }



async def process_audio_task(task_id: str, audio_path: str,
                             colormap: str, scale: str, fft_size: int, mode: str = "classic", use_gpu: bool = True):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –∞—É–¥—ñ–æ"""
    try:
        tasks_status[task_id]["status"] = "processing"
        tasks_status[task_id]["message"] = "–û–±—Ä–æ–±–∫–∞ –∞—É–¥—ñ–æ..."
        tasks_status[task_id]["progress"] = 10

        base_name = Path(audio_path).stem
        output_2d = OUTPUT_DIR / f"{task_id}_{base_name}_2d.png"

        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è 2D —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏
        tasks_status[task_id]["message"] = "–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è 2D —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏..."
        tasks_status[task_id]["progress"] = 50
        info_2d = generate_2d_spectrogram(audio_path, str(output_2d), colormap, scale, fft_size, mode, use_gpu)

        # –û—á–∏—â–µ–Ω–Ω—è —Ç–∏–º—á–∞—Å–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É
        tasks_status[task_id]["progress"] = 90
        os.remove(audio_path)

        # –ó–∞–≤–µ—Ä—à–µ–Ω–Ω—è
        tasks_status[task_id]["status"] = "completed"
        tasks_status[task_id]["progress"] = 100
        tasks_status[task_id]["message"] = "–û–±—Ä–æ–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!"

        result = {
            "spectrogram_2d": {
                "url": f"/outputs/{output_2d.name}",
                "filename": output_2d.name,
                **info_2d
            }
        }

        tasks_status[task_id]["result"] = result

    except Exception as e:
        tasks_status[task_id]["status"] = "error"
        tasks_status[task_id]["message"] = f"–ü–æ–º–∏–ª–∫–∞: {str(e)}"
        # –û—á–∏—â–µ–Ω–Ω—è –ø—Ä–∏ –ø–æ–º–∏–ª—Ü—ñ
        if os.path.exists(audio_path):
            os.remove(audio_path)


@app.get("/", response_class=HTMLResponse)
async def root():
    """–ì–æ–ª–æ–≤–Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∞"""
    html_path = STATIC_DIR / "index.html"
    if html_path.exists():
        return html_path.read_text(encoding='utf-8')
    return HTMLResponse("<h1>Audio Spectrogram Service</h1><p>–ü–æ–º—ñ—Å—Ç—ñ—Ç—å index.html —É –ø–∞–ø–∫—É static</p>")


@app.get("/api/status")
async def get_service_status():
    """–°—Ç–∞—Ç—É—Å —Å–µ—Ä–≤—ñ—Å—É"""
    return {
        "status": "online",
        "gpu_available": GPU_AVAILABLE,
        "supported_formats": list(SUPPORTED_FORMATS),
        "max_file_size_mb": MAX_FILE_SIZE // (1024 * 1024)
    }


@app.post("/api/upload")
async def upload_audio(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    colormap: str = "magma",
    scale: str = "linear",
    fft_size: int = 2048,
    mode: str = "classic",
    use_gpu: bool = True
):
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ—Ñ–∞–π–ª—É –¥–ª—è –æ–±—Ä–æ–±–∫–∏
    """
    # –í–∞–ª—ñ–¥–∞—Ü—ñ—è
    if not validate_audio_file(file.filename):
        raise HTTPException(
            status_code=400,
            detail=f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç. –î–æ–∑–≤–æ–ª–µ–Ω—ñ: {', '.join(SUPPORTED_FORMATS)}"
        )

    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä–æ–∑–º—ñ—Ä—É
    file.file.seek(0, 2)
    file_size = file.file.tell()
    file.file.seek(0)

    if file_size > MAX_FILE_SIZE:
        raise HTTPException(
            status_code=400,
            detail=f"–§–∞–π–ª –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∏–π. –ú–∞–∫—Å–∏–º—É–º: {MAX_FILE_SIZE // (1024*1024)} MB"
        )

    # –í–∞–ª—ñ–¥–∞—Ü—ñ—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    if scale.lower() not in ["linear", "log", "mel"]:
        raise HTTPException(status_code=400, detail="–ú–∞—Å—à—Ç–∞–± –º–∞—î –±—É—Ç–∏ 'linear', 'log' –∞–±–æ 'mel'")

    if fft_size not in [256, 512, 1024, 2048, 4096, 8192, 16384]:
        raise HTTPException(status_code=400, detail="FFT Size –º–∞—î –±—É—Ç–∏ 256, 512, 1024, 2048, 4096, 8192 –∞–±–æ 16384")

    if mode not in ["classic", "sharp", "sharper"]:
        raise HTTPException(status_code=400, detail="Mode –º–∞—î –±—É—Ç–∏ 'classic', 'sharp' –∞–±–æ 'sharper'")

    # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è ID –∑–∞–≤–¥–∞–Ω–Ω—è (–Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ç–∞–π–º—Å—Ç–µ–º–ø—É)
    task_id = generate_task_id()

    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É
    file_ext = Path(file.filename).suffix
    temp_path = UPLOAD_DIR / f"{task_id}{file_ext}"

    with open(temp_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å—Ç–∞—Ç—É—Å—É
    tasks_status[task_id] = {
        "task_id": task_id,
        "status": "pending",
        "progress": 0,
        "message": "–ó–∞–≤–¥–∞–Ω–Ω—è —Å—Ç–≤–æ—Ä–µ–Ω–æ",
        "result": None
    }

    # –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ—ó –æ–±—Ä–æ–±–∫–∏
    background_tasks.add_task(
        process_audio_task,
        task_id,
        str(temp_path),
        colormap,
        scale.lower(),
        fft_size,
        mode,
        use_gpu
    )

    return {"task_id": task_id, "message": "–§–∞–π–ª –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ, –æ–±—Ä–æ–±–∫–∞ —Ä–æ–∑–ø–æ—á–∞—Ç–∞"}


@app.post("/api/preview")
async def generate_preview(
    file: UploadFile = File(...),
    colormap: str = "magma",
    scale: str = "linear",
    fft_size: int = 2048,
    mode: str = "classic",
    use_gpu: bool = True
):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø—Ä–µ–≤ º—é —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏ (320px) –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —á–∞—Å—É
    """
    # –õ–æ–≥—É–≤–∞–Ω–Ω—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –ø—Ä–µ–≤ º—é: colormap={colormap}, scale={scale}, fft_size={fft_size}, mode={mode}")

    # –í–∞–ª—ñ–¥–∞—Ü—ñ—è
    if not validate_audio_file(file.filename):
        raise HTTPException(
            status_code=400,
            detail=f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç. –î–æ–∑–≤–æ–ª–µ–Ω—ñ: {', '.join(SUPPORTED_FORMATS)}"
        )

    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä–æ–∑–º—ñ—Ä—É
    file.file.seek(0, 2)
    file_size = file.file.tell()
    file.file.seek(0)

    if file_size > MAX_FILE_SIZE:
        raise HTTPException(
            status_code=400,
            detail=f"–§–∞–π–ª –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∏–π. –ú–∞–∫—Å–∏–º—É–º: {MAX_FILE_SIZE // (1024*1024)} MB"
        )

    # –í–∞–ª—ñ–¥–∞—Ü—ñ—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    if scale.lower() not in ["linear", "log", "mel"]:
        raise HTTPException(status_code=400, detail="–ú–∞—Å—à—Ç–∞–± –º–∞—î –±—É—Ç–∏ 'linear', 'log' –∞–±–æ 'mel'")

    if fft_size not in [256, 512, 1024, 2048, 4096, 8192, 16384]:
        raise HTTPException(status_code=400, detail="FFT Size –º–∞—î –±—É—Ç–∏ 256, 512, 1024, 2048, 4096, 8192 –∞–±–æ 16384")

    if mode not in ["classic", "sharp", "sharper"]:
        raise HTTPException(status_code=400, detail="Mode –º–∞—î –±—É—Ç–∏ 'classic', 'sharp' –∞–±–æ 'sharper'")

    try:
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ç–∏–º—á–∞—Å–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É
        temp_id = generate_task_id()
        temp_path = UPLOAD_DIR / f"{temp_id}{Path(file.filename).suffix}"

        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —É–Ω—ñ–∫–∞–ª—å–Ω–æ–≥–æ —ñ–º–µ–Ω—ñ —Ñ–∞–π–ª—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
        params_hash = generate_preview_hash(colormap, scale, fft_size, mode)
        preview_path = OUTPUT_DIR / f"{temp_id}_{params_hash}_preview.png"

        with open(temp_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)

        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø—Ä–µ–≤ º—é
        info = generate_2d_preview(str(temp_path), str(preview_path), colormap, scale, fft_size, mode, use_gpu)

        # –û—á–∏—â–µ–Ω–Ω—è —Ç–∏–º—á–∞—Å–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É
        os.remove(temp_path)

        print(f"‚úì –ü—Ä–µ–≤ º—é –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ: {preview_path.name}")

        return {
            "preview_url": f"/outputs/{preview_path.name}",
            "filename": preview_path.name,
            **info
        }

    except Exception as e:
        print(f"‚úó –ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –ø—Ä–µ–≤ º—é: {str(e)}")
        raise HTTPException(status_code=500, detail=f"–ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –ø—Ä–µ–≤ º—é: {str(e)}")


@app.get("/api/task/{task_id}")
async def get_task_status(task_id: str):
    """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–∞—Ç—É—Å—É –∑–∞–≤–¥–∞–Ω–Ω—è"""
    if task_id not in tasks_status:
        raise HTTPException(status_code=404, detail="–ó–∞–≤–¥–∞–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
    return tasks_status[task_id]


@app.post("/api/download-4k")
async def download_4k_spectrogram(
    file: UploadFile = File(...),
    colormap: str = "magma",
    scale: str = "linear",
    fft_size: int = 2048,
    mode: str = "classic",
    use_gpu: bool = True
):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è 4K —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏ (3840x2160)
    """
    # –í–∞–ª—ñ–¥–∞—Ü—ñ—è
    if not validate_audio_file(file.filename):
        raise HTTPException(
            status_code=400,
            detail=f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç. –î–æ–∑–≤–æ–ª–µ–Ω—ñ: {', '.join(SUPPORTED_FORMATS)}"
        )

    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä–æ–∑–º—ñ—Ä—É
    file.file.seek(0, 2)
    file_size = file.file.tell()
    file.file.seek(0)

    if file_size > MAX_FILE_SIZE:
        raise HTTPException(
            status_code=400,
            detail=f"–§–∞–π–ª –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∏–π. –ú–∞–∫—Å–∏–º—É–º: {MAX_FILE_SIZE // (1024*1024)} MB"
        )

    # –í–∞–ª—ñ–¥–∞—Ü—ñ—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    if scale.lower() not in ["linear", "log", "mel"]:
        raise HTTPException(status_code=400, detail="–ú–∞—Å—à—Ç–∞–± –º–∞—î –±—É—Ç–∏ 'linear', 'log' –∞–±–æ 'mel'")

    if fft_size not in [256, 512, 1024, 2048, 4096, 8192, 16384]:
        raise HTTPException(status_code=400, detail="FFT Size –º–∞—î –±—É—Ç–∏ 256, 512, 1024, 2048, 4096, 8192 –∞–±–æ 16384")

    if mode not in ["classic", "sharp", "sharper"]:
        raise HTTPException(status_code=400, detail="Mode –º–∞—î –±—É—Ç–∏ 'classic', 'sharp' –∞–±–æ 'sharper'")

    try:
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ç–∏–º—á–∞—Å–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É
        temp_id = generate_task_id()
        temp_path = UPLOAD_DIR / f"{temp_id}{Path(file.filename).suffix}"
        output_path = OUTPUT_DIR / f"{temp_id}_4k.png"

        with open(temp_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)

        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è 4K —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏
        generate_2d_spectrogram(str(temp_path), str(output_path), colormap, scale, fft_size, mode, use_gpu)

        # –û—á–∏—â–µ–Ω–Ω—è —Ç–∏–º—á–∞—Å–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É
        os.remove(temp_path)

        # –ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è —Ñ–∞–π–ª—É –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        return FileResponse(
            path=str(output_path),
            filename=f"spectrogram_4k_{temp_id}.png",
            media_type="image/png"
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó 4K: {str(e)}")


@app.get("/api/download/{filename}")
async def download_file(filename: str):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É"""
    file_path = OUTPUT_DIR / filename
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="–§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
    
    media_type = "image/png" if filename.endswith(".png") else "application/octet-stream"
    return FileResponse(
        path=str(file_path),
        filename=filename,
        media_type=media_type
    )


@app.delete("/api/cleanup")
async def cleanup_old_files(max_age_hours: int = 24):
    """–û—á–∏—â–µ–Ω–Ω—è —Å—Ç–∞—Ä–∏—Ö —Ñ–∞–π–ª—ñ–≤"""
    cutoff = datetime.now() - timedelta(hours=max_age_hours)
    removed = 0
    
    for directory in [OUTPUT_DIR, UPLOAD_DIR]:
        for file in directory.iterdir():
            if file.is_file():
                mtime = datetime.fromtimestamp(file.stat().st_mtime)
                if mtime < cutoff:
                    file.unlink()
                    removed += 1
    
    return {"removed_files": removed}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
