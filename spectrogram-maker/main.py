"""
Audio Spectrogram Web Service
–í–µ–±-—Å–µ—Ä–≤—ñ—Å –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –∞—É–¥—ñ–æ—Ñ–∞–π–ª—ñ–≤ –∑ GPU-–ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è–º
–ì–µ–Ω–µ—Ä—É—î 2D —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏
"""

import os
import asyncio
from io import BytesIO
from pathlib import Path
from typing import Optional
import numpy as np
from fastapi import FastAPI, UploadFile, File, HTTPException, BackgroundTasks
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, HTMLResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import librosa
import librosa.display
import matplotlib
matplotlib.use('Agg')  # –î–ª—è —Å–µ—Ä–≤–µ—Ä–Ω–æ–≥–æ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥—É
import matplotlib.pyplot as plt
from matplotlib.ticker import ScalarFormatter
from matplotlib.colors import LinearSegmentedColormap
import soundfile as sf
from PIL import Image, ImageEnhance, ImageFilter
from pydantic import BaseModel
from datetime import datetime, timedelta
import shutil
import time
import hashlib

# –°–ø—Ä–æ–±–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ CuPy –¥–ª—è GPU –æ–±—Ä–æ–±–∫–∏
try:
    import cupy as cp
    GPU_AVAILABLE = True
    print("‚úì GPU (CuPy) –¥–æ—Å—Ç—É–ø–Ω–∏–π –¥–ª—è –æ–±—Ä–æ–±–∫–∏")
except ImportError:
    cp = np
    GPU_AVAILABLE = False
    print("‚úó GPU –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è CPU (NumPy)")

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–æ–¥–∞—Ç–∫—É
app = FastAPI(
    title="Audio Spectrogram Service",
    description="–í–µ–±-—Å–µ—Ä–≤—ñ—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó 2D —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º –∑ GPU-–ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è–º",
    version="1.0.0"
)

# CORS –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥—É
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
BASE_DIR = Path(__file__).parent
UPLOAD_DIR = BASE_DIR / "uploads"
OUTPUT_DIR = BASE_DIR / "outputs"
STATIC_DIR = BASE_DIR / "dist"

UPLOAD_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)
STATIC_DIR.mkdir(exist_ok=True)

# –°—Ç–∞—Ç–∏—á–Ω—ñ —Ñ–∞–π–ª–∏
app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")
app.mount("/outputs", StaticFiles(directory=str(OUTPUT_DIR)), name="outputs")

# –ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ —Ñ–æ—Ä–º–∞—Ç–∏
SUPPORTED_FORMATS = {'.mp3', '.wav', '.flac', '.ogg', '.m4a', '.aac', '.wma'}
MAX_FILE_SIZE = 100 * 1024 * 1024  # 100 MB

IMAGE_EXT = ".jpg"
IMAGE_FORMAT = "jpeg"
JPEG_QUALITY = 100
JPEG_SUBSAMPLING = 0

FINAL_FIGSIZE = (22.8, 12.8)
FINAL_DPI = 168
PREVIEW_WIDTH_PX = 320
PREVIEW_DPI = 160
PREVIEW_FIGSIZE = (
    PREVIEW_WIDTH_PX / PREVIEW_DPI,
    (PREVIEW_WIDTH_PX / PREVIEW_DPI) * (FINAL_FIGSIZE[1] / FINAL_FIGSIZE[0]),
)
PREVIEW_FONT_SCALE = 0.5
FREQ_MIN_HZ = 0.0
LOG_MIN_HZ = 20.0
LOG_LINTHRESH_HZ = 20.0
LOG_BASE = 10
MEL_LINTHRESH_HZ = 200.0
MEL_LOG_BASE = 10
MEL_TICK_HZ = (20, 50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000)
LOG_TICK_HZ = (20, 50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000)
MEL_BANDS = 384
DB_FLOOR = -120.0
AUTO_FREQ_MAX_DB = -60.0
AUTO_FREQ_MAX_PAD_HZ = 100.0

# –ó–±–µ—Ä—ñ–≥–∞–Ω–Ω—è —Å—Ç–∞—Ç—É—Å—ñ–≤ –∑–∞–≤–¥–∞–Ω—å
tasks_status = {}


class TaskStatus(BaseModel):
    task_id: str
    status: str  # pending, processing, completed, error
    progress: int
    message: str
    result: Optional[dict] = None


def validate_audio_file(filename: str) -> bool:
    """–í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ñ–æ—Ä–º–∞—Ç—É –∞—É–¥—ñ–æ—Ñ–∞–π–ª—É"""
    ext = Path(filename).suffix.lower()
    return ext in SUPPORTED_FORMATS


def generate_task_id() -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —É–Ω—ñ–∫–∞–ª—å–Ω–æ–≥–æ ID –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ç–∞–π–º—Å—Ç–µ–º–ø—É"""
    return str(int(time.time() * 1000))


def generate_preview_hash(colormap: str, scale: str, fft_size: int, mode: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ö–µ—à—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –ø—Ä–µ–≤ º—é"""
    params = f"{colormap}_{scale}_{fft_size}_{mode}"
    return hashlib.md5(params.encode()).hexdigest()[:8]


MODE_CONFIGS = {
    "classic": {
        "top_db": None,
        "hop_div": 4,
        "preemphasis": None,
        "vmax_percentile": None,
    },
    "sharp": {
        "top_db": 80,
        "hop_div": 8,
        "preemphasis": 0.97,
        "vmax_percentile": 99.7,
    },
    "sharper": {
        "top_db": 50,
        "hop_div": 16,
        "preemphasis": 0.98,
        "vmax_percentile": 99.5,
    },
}


def get_mode_config(mode: str) -> dict:
    """–ü–æ–≤–µ—Ä—Ç–∞—î –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è —Ä–µ–∂–∏–º—É –ø—ñ–¥—Å–∏–ª–µ–Ω–Ω—è."""
    return MODE_CONFIGS.get(mode, MODE_CONFIGS["classic"])


def compute_spectrogram_gpu(audio: np.ndarray, sr: int, n_fft: int = 2048,
                            hop_length: int = 512, use_gpu: bool = True) -> np.ndarray:
    """
    –û–±—á–∏—Å–ª–µ–Ω–Ω—è —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º GPU (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∏–π)
    use_gpu: —è–∫—â–æ True - –Ω–∞–º–∞–≥–∞—î–º–æ—Å—å –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ GPU, —è–∫—â–æ False - –∑–∞–≤–∂–¥–∏ CPU
    """
    if GPU_AVAILABLE and use_gpu:
        # –ü–µ—Ä–µ–Ω–æ—Å–∏–º–æ –¥–∞–Ω—ñ –Ω–∞ GPU
        audio_gpu = cp.asarray(audio)

        # STFT –Ω–∞ GPU
        n_frames = 1 + (len(audio_gpu) - n_fft) // hop_length
        stft_matrix = cp.zeros((n_fft // 2 + 1, n_frames), dtype=cp.complex64)

        window = cp.hanning(n_fft).astype(cp.float32)

        for i in range(n_frames):
            start = i * hop_length
            frame = audio_gpu[start:start + n_fft]
            if len(frame) < n_fft:
                frame = cp.pad(frame, (0, n_fft - len(frame)))
            windowed = frame * window
            spectrum = cp.fft.rfft(windowed)
            stft_matrix[:, i] = spectrum

        # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è —É –¥–µ—Ü–∏–±–µ–ª–∏
        magnitude = cp.abs(stft_matrix)
        spectrogram_db = 20 * cp.log10(cp.maximum(magnitude, 1e-10))
        spectrogram_db = spectrogram_db - spectrogram_db.max()
        spectrogram_db = cp.maximum(spectrogram_db, DB_FLOOR)

        # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –Ω–∞ CPU
        return cp.asnumpy(spectrogram_db)
    else:
        # CPU fallback –∑ librosa
        stft = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length)
        spectrogram_db = librosa.amplitude_to_db(
            np.abs(stft),
            ref=np.max,
            top_db=abs(DB_FLOOR)
        )
        return spectrogram_db


def get_display_bounds(sr: int, scale: str) -> tuple[float, float, float]:
    """–ü–æ–≤–µ—Ä—Ç–∞—î –º–µ–∂—ñ —á–∞—Å—Ç–æ—Ç–Ω–æ—ó –æ—Å—ñ —Ç–∞ fmax –¥–ª—è –¥–∞–Ω–∏—Ö."""
    nyquist = sr / 2.0
    display_min = LOG_MIN_HZ if scale in ("log", "mel") else FREQ_MIN_HZ
    display_max = nyquist
    if display_max <= display_min:
        display_max = display_min + 1.0

    fmax_data = min(display_max, nyquist)
    if fmax_data <= display_min:
        fmax_data = display_min + 1.0

    return display_min, display_max, fmax_data


def compute_mel_spectrogram(audio: np.ndarray, sr: int, n_fft: int,
                            hop_length: int, fmin: float, fmax: float,
                            mel_bins: int = MEL_BANDS, htk: bool = True,
                            norm: Optional[str] = None) -> np.ndarray:
    """–û–±—á–∏—Å–ª–µ–Ω–Ω—è mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏ –∑ –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è–º —É dB."""
    mel_bins = min(mel_bins, n_fft // 2 + 1)
    mel_power = librosa.feature.melspectrogram(
        y=audio,
        sr=sr,
        n_fft=n_fft,
        hop_length=hop_length,
        n_mels=mel_bins,
        fmin=fmin,
        fmax=fmax,
        htk=htk,
        norm=norm,
        power=2.0
    )
    mel_db = librosa.power_to_db(mel_power, ref=np.max, top_db=abs(DB_FLOOR))
    return mel_db


def apply_image_enhancements(img: Image.Image, mode: str = "classic") -> Image.Image:
    """
    –ü–æ—Å–∏–ª–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫–∏.
    mode: "classic" - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è, "sharp" - –ø–æ—Å–∏–ª–µ–Ω–µ, "sharper" - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ—Å–∏–ª–µ–Ω–µ.
    """
    if mode == "classic":
        return img

    try:
        if mode == "sharp":
            # –ü–æ—Å–∏–ª–µ–Ω–Ω—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—ñ
            enhancer_contrast = ImageEnhance.Contrast(img)
            img = enhancer_contrast.enhance(1.3)

            # –ü–æ—Å–∏–ª–µ–Ω–Ω—è –Ω–∞—Å–∏—á–µ–Ω–æ—Å—Ç—ñ
            enhancer_color = ImageEnhance.Color(img)
            img = enhancer_color.enhance(1.2)

            # –õ–µ–≥–∫–µ –ø–æ—Å–∏–ª–µ–Ω–Ω—è —Ä—ñ–∑–∫–æ—Å—Ç—ñ
            enhancer_sharpness = ImageEnhance.Sharpness(img)
            img = enhancer_sharpness.enhance(1.5)
            img = img.filter(ImageFilter.UnsharpMask(radius=1.2, percent=130, threshold=3))

        elif mode == "sharper":
            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–µ –ø–æ—Å–∏–ª–µ–Ω–Ω—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—ñ
            enhancer_contrast = ImageEnhance.Contrast(img)
            img = enhancer_contrast.enhance(1.6)

            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–µ –ø–æ—Å–∏–ª–µ–Ω–Ω—è –Ω–∞—Å–∏—á–µ–Ω–æ—Å—Ç—ñ
            enhancer_color = ImageEnhance.Color(img)
            img = enhancer_color.enhance(1.5)

            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–µ –ø–æ—Å–∏–ª–µ–Ω–Ω—è —Ä—ñ–∑–∫–æ—Å—Ç—ñ
            enhancer_sharpness = ImageEnhance.Sharpness(img)
            img = enhancer_sharpness.enhance(2.0)
            img = img.filter(ImageFilter.UnsharpMask(radius=1.8, percent=180, threshold=2))

            # –ü–æ—Å–∏–ª–µ–Ω–Ω—è —è—Å–∫—Ä–∞–≤–æ—Å—Ç—ñ
            enhancer_brightness = ImageEnhance.Brightness(img)
            img = enhancer_brightness.enhance(1.1)

    except Exception as e:
        print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ—Å–∏–ª–µ–Ω–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {e}")

    return img


def render_spectrogram_figure(
    spectrogram_db: np.ndarray,
    sr: int,
    hop_length: int,
    *,
    colormap: str,
    scale: str,
    vmin: float,
    vmax: float,
    figsize: tuple,
    dpi: int,
    font_scale: float,
    shading: str = "nearest",
    htk: bool = False,
):
    """–°—Ç–≤–æ—Ä—é—î —Ñ—ñ–≥—É—Ä—É —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏ –∑ —É–∑–≥–æ–¥–∂–µ–Ω–∏–º —Å—Ç–∏–ª–µ–º."""
    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)

    # –ö–∞—Å—Ç–æ–º–Ω–∞ –∫–æ–ª—å–æ—Ä–æ–≤–∞ –∫–∞—Ä—Ç–∞
    if colormap == "custom":
        colors = ['#0d0221', '#0d1b2a', '#1b263b', '#415a77',
                  '#778da9', '#e0e1dd', '#ff6b6b', '#ffd93d']
        custom_cmap = LinearSegmentedColormap.from_list("audio_spectrum", colors)
        cmap = custom_cmap
    elif colormap == "gray":
        cmap = "gray"
    else:
        cmap = colormap

    # –í–∏–±—ñ—Ä –æ—Å—ñ Y –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Ç–∏–ø—É –º–∞—Å—à—Ç–∞–±–∞
    y_axis_map = {
        "linear": "hz",
        "log": "hz",
        "mel": "mel",
    }
    y_axis = y_axis_map.get(scale, "hz")

    display_min, display_max, fmax_data = get_display_bounds(sr, scale)

    if scale in ("linear", "log") and AUTO_FREQ_MAX_DB is not None:
        n_fft = 2 * (spectrogram_db.shape[0] - 1)
        freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)
        max_db = np.max(spectrogram_db, axis=1)
        valid = np.where(max_db > AUTO_FREQ_MAX_DB)[0]
        if valid.size:
            auto_max = freqs[valid[-1]] + AUTO_FREQ_MAX_PAD_HZ
            display_max = min(display_max, auto_max)
            if display_max <= display_min:
                display_max = min(fmax_data, display_min + 1.0)
            fmax_data = min(fmax_data, display_max)

    img = librosa.display.specshow(
        spectrogram_db,
        sr=sr,
        hop_length=hop_length,
        x_axis='time',
        y_axis=y_axis,
        cmap=cmap,
        vmin=vmin,
        vmax=vmax,
        fmin=display_min,
        fmax=fmax_data,
        shading=shading,
        antialiased=False,
        htk=htk,
        ax=ax
    )

    label_size = max(5, int(round(12 * font_scale)))
    title_size = max(6, int(round(14 * font_scale)))
    tick_size = max(5, int(round(10 * font_scale)))
    cbar_tick_size = max(5, int(round(9 * font_scale)))
    cbar_label_size = max(5, int(round(10 * font_scale)))
    title_pad = max(3, int(round(10 * font_scale)))

    # –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è labels –æ—Å–µ–π
    y_label_map = {
        "linear": "Frequency (Hz)",
        "log": "Frequency (Hz, pseudo log)",
        "mel": "Mel Spectrogram (HTK, Hz)",
        "bark": "Bark frequency"
    }
    y_label = y_label_map.get(scale, "Frequency (Hz)")

    ax.set_xlabel('Time (s)', fontsize=label_size, color='white')
    ax.set_ylabel(y_label, fontsize=label_size, color='white')
    ax.set_title('Audio Spectrogram', fontsize=title_size, color='white', pad=title_pad)

    # –°—Ç–∏–ª—ñ–∑–∞—Ü—ñ—è
    fig.patch.set_facecolor('#0d0221')
    ax.set_facecolor('#0d0221')
    ax.tick_params(colors='white', labelsize=tick_size)
    for spine in ax.spines.values():
        spine.set_color('#415a77')

    if scale == "log":
        ax.set_yscale('symlog', linthresh=LOG_LINTHRESH_HZ, base=LOG_BASE)
    elif scale == "mel":
        ax.set_yscale('symlog', linthresh=MEL_LINTHRESH_HZ, base=MEL_LOG_BASE)

    axis_min = display_min
    axis_max = display_max

    ax.set_ylim(axis_min, axis_max)

    if scale == "log":
        ticks = [tick for tick in LOG_TICK_HZ if display_min <= tick <= display_max]
        if not ticks:
            ticks = [display_min, display_max]
        ax.set_yticks(sorted(set(round(tick, 6) for tick in ticks)))
        formatter = ScalarFormatter()
        formatter.set_scientific(False)
        formatter.set_useOffset(False)
        ax.yaxis.set_major_formatter(formatter)
    elif scale == "mel":
        ticks = [tick for tick in MEL_TICK_HZ if display_min <= tick <= display_max]
        if not ticks:
            ticks = [display_min, display_max]
        ax.set_yticks(sorted(set(round(tick, 6) for tick in ticks)))
        formatter = ScalarFormatter()
        formatter.set_scientific(False)
        formatter.set_useOffset(False)
        ax.yaxis.set_major_formatter(formatter)
    else:
        ticks = [tick for tick in ax.get_yticks() if display_min <= tick <= display_max]
        if not ticks:
            ticks = [display_min, display_max]
        ax.set_yticks(sorted(set(round(tick, 6) for tick in ticks)))

    # –ö–æ–ª—å–æ—Ä–æ–≤–∞ —à–∫–∞–ª–∞
    cbar = fig.colorbar(img, ax=ax, format='%+2.0f dB')
    cbar.ax.yaxis.set_tick_params(color='white', labelsize=cbar_tick_size)
    cbar.outline.set_edgecolor('#415a77')
    plt.setp(plt.getp(cbar.ax.axes, 'yticklabels'), color='white')
    cbar.set_label('Intensity (dB)', color='white', fontsize=cbar_label_size)

    plt.tight_layout()
    return fig


def save_figure_image(fig: plt.Figure, output_path: str, mode: str) -> None:
    """–ó–±–µ—Ä—ñ–≥–∞—î —Ñ—ñ–≥—É—Ä—É –≤ –ø–æ—Ç—Ä—ñ–±–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –∑ –æ–¥–Ω–∏–º JPEG-–∫–æ–¥—É–≤–∞–Ω–Ω—è–º."""
    buffer = BytesIO()
    fig.savefig(
        buffer,
        format="png",
        facecolor=fig.get_facecolor(),
        edgecolor='none',
        bbox_inches='tight'
    )
    plt.close(fig)
    buffer.seek(0)
    img = Image.open(buffer)
    img.load()
    buffer.close()

    if IMAGE_FORMAT == "jpeg":
        img = img.convert("RGB")

    img = apply_image_enhancements(img, mode)

    if IMAGE_FORMAT == "jpeg":
        img.save(
            output_path,
            format="JPEG",
            quality=JPEG_QUALITY,
            subsampling=JPEG_SUBSAMPLING,
            optimize=False
        )
    else:
        img.save(output_path, format="PNG", optimize=False)


def generate_2d_spectrogram(audio_path: str, output_path: str,
                            colormap: str = "magma", scale: str = "linear", n_fft: int = 2048,
                            mode: str = "classic", use_gpu: bool = True) -> dict:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è 2D —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —è–∫ JPEG
    scale: "linear", "log", "mel"
    n_fft: FFT size (1024, 2048, 4096, 8192, 16384)
    mode: "classic", "sharp", "sharper" - –¥–∏–Ω–∞–º—ñ—á–Ω–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω
    use_gpu: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ GPU –æ–±—Ä–æ–±–∫—É —è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∞
    """
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ
    audio, sr = librosa.load(audio_path, sr=None, mono=True)
    duration = librosa.get_duration(y=audio, sr=sr)

    mode_config = get_mode_config(mode)

    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏
    hop_length = max(1, n_fft // mode_config["hop_div"])
    if mode_config["preemphasis"] is not None:
        audio = librosa.effects.preemphasis(audio, coef=mode_config["preemphasis"])
    display_min, _, fmax_data = get_display_bounds(sr, scale)
    shading = "nearest"
    htk = False
    if scale == "mel":
        spectrogram_db = compute_mel_spectrogram(
            audio,
            sr,
            n_fft,
            hop_length,
            display_min,
            fmax_data
        )
        shading = "gouraud"
        htk = True
    else:
        spectrogram_db = compute_spectrogram_gpu(audio, sr, n_fft, hop_length, use_gpu)

    # –ö–æ–Ω—Ç—Ä–æ–ª—å –¥–∏–Ω–∞–º—ñ—á–Ω–æ–≥–æ –¥—ñ–∞–ø–∞–∑–æ–Ω—É –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ Mode
    vmax = spectrogram_db.max()
    vmax_percentile = mode_config["vmax_percentile"]
    if vmax_percentile is not None:
        vmax = np.percentile(spectrogram_db, vmax_percentile)

    if mode_config["top_db"] is not None:
        vmin = vmax - mode_config["top_db"]
    else:
        vmin = spectrogram_db.min()
    vmin = min(vmin, DB_FLOOR)
    spectrogram_db = np.maximum(spectrogram_db, vmin)

    fig = render_spectrogram_figure(
        spectrogram_db,
        sr,
        hop_length,
        colormap=colormap,
        scale=scale,
        vmin=vmin,
        vmax=vmax,
        figsize=FINAL_FIGSIZE,
        dpi=FINAL_DPI,
        font_scale=1.0,
        shading=shading,
        htk=htk
    )
    save_figure_image(fig, output_path, mode)

    return {
        "duration": round(duration, 2),
        "sample_rate": sr,
        "frequency_bins": spectrogram_db.shape[0],
        "time_frames": spectrogram_db.shape[1]
    }


def generate_2d_preview(audio_path: str, output_path: str,
                       colormap: str = "magma", scale: str = "linear", n_fft: int = 2048,
                       mode: str = "classic", use_gpu: bool = True) -> dict:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –Ω–µ–≤–µ–ª–∏–∫–æ–≥–æ –ø—Ä–µ–≤ º—é —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏ (320px —à–∏—Ä–∏–Ω–∏) —É JPEG
    –®–≤–∏–¥—à–∞ –≤–µ—Ä—Å—ñ—è –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —á–∞—Å—É
    mode: "classic", "sharp", "sharper" - –¥–∏–Ω–∞–º—ñ—á–Ω–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω
    use_gpu: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ GPU –æ–±—Ä–æ–±–∫—É —è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∞
    """
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ
    audio, sr = librosa.load(audio_path, sr=None, mono=True)
    duration = librosa.get_duration(y=audio, sr=sr)

    mode_config = get_mode_config(mode)

    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏
    hop_length = max(1, n_fft // mode_config["hop_div"])
    if mode_config["preemphasis"] is not None:
        audio = librosa.effects.preemphasis(audio, coef=mode_config["preemphasis"])
    display_min, _, fmax_data = get_display_bounds(sr, scale)
    shading = "nearest"
    htk = False
    if scale == "mel":
        spectrogram_db = compute_mel_spectrogram(
            audio,
            sr,
            n_fft,
            hop_length,
            display_min,
            fmax_data
        )
        shading = "gouraud"
        htk = True
    else:
        spectrogram_db = compute_spectrogram_gpu(audio, sr, n_fft, hop_length, use_gpu)

    # –ö–æ–Ω—Ç—Ä–æ–ª—å –¥–∏–Ω–∞–º—ñ—á–Ω–æ–≥–æ –¥—ñ–∞–ø–∞–∑–æ–Ω—É –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ Mode
    vmax = spectrogram_db.max()
    vmax_percentile = mode_config["vmax_percentile"]
    if vmax_percentile is not None:
        vmax = np.percentile(spectrogram_db, vmax_percentile)

    if mode_config["top_db"] is not None:
        vmin = vmax - mode_config["top_db"]
    else:
        vmin = spectrogram_db.min()
    vmin = min(vmin, DB_FLOOR)
    spectrogram_db = np.maximum(spectrogram_db, vmin)

    fig = render_spectrogram_figure(
        spectrogram_db,
        sr,
        hop_length,
        colormap=colormap,
        scale=scale,
        vmin=vmin,
        vmax=vmax,
        figsize=PREVIEW_FIGSIZE,
        dpi=PREVIEW_DPI,
        font_scale=PREVIEW_FONT_SCALE,
        shading=shading,
        htk=htk
    )
    save_figure_image(fig, output_path, mode)

    return {
        "duration": round(duration, 2),
        "sample_rate": sr,
        "frequency_bins": spectrogram_db.shape[0],
        "time_frames": spectrogram_db.shape[1]
    }



async def process_audio_task(task_id: str, audio_path: str, original_stem: str,
                             colormap: str, scale: str, fft_size: int, mode: str = "classic", use_gpu: bool = True):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –∞—É–¥—ñ–æ"""
    try:
        tasks_status[task_id]["status"] = "processing"
        tasks_status[task_id]["message"] = "–û–±—Ä–æ–±–∫–∞ –∞—É–¥—ñ–æ..."
        tasks_status[task_id]["progress"] = 10

        safe_stem = Path(original_stem).stem or "audio"
        output_2d = OUTPUT_DIR / f"{task_id}_{safe_stem}_2d{IMAGE_EXT}"

        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è 2D —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏
        tasks_status[task_id]["message"] = "–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è 2D —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏..."
        tasks_status[task_id]["progress"] = 50
        info_2d = generate_2d_spectrogram(audio_path, str(output_2d), colormap, scale, fft_size, mode, use_gpu)

        # –û—á–∏—â–µ–Ω–Ω—è —Ç–∏–º—á–∞—Å–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É
        tasks_status[task_id]["progress"] = 90
        os.remove(audio_path)

        # –ó–∞–≤–µ—Ä—à–µ–Ω–Ω—è
        tasks_status[task_id]["status"] = "completed"
        tasks_status[task_id]["progress"] = 100
        tasks_status[task_id]["message"] = "–û–±—Ä–æ–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!"

        result = {
            "spectrogram_2d": {
                "url": f"/outputs/{output_2d.name}",
                "filename": output_2d.name,
                **info_2d
            }
        }

        tasks_status[task_id]["result"] = result

    except Exception as e:
        tasks_status[task_id]["status"] = "error"
        tasks_status[task_id]["message"] = f"–ü–æ–º–∏–ª–∫–∞: {str(e)}"
        # –û—á–∏—â–µ–Ω–Ω—è –ø—Ä–∏ –ø–æ–º–∏–ª—Ü—ñ
        if os.path.exists(audio_path):
            os.remove(audio_path)


@app.get("/", response_class=HTMLResponse)
async def root():
    """–ì–æ–ª–æ–≤–Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∞"""
    html_path = STATIC_DIR / "index.html"
    if html_path.exists():
        return html_path.read_text(encoding='utf-8')
    return HTMLResponse("<h1>Audio Spectrogram Service</h1><p>–ü–æ–º—ñ—Å—Ç—ñ—Ç—å index.html —É –ø–∞–ø–∫—É static</p>")


@app.get("/api/status")
async def get_service_status():
    """–°—Ç–∞—Ç—É—Å —Å–µ—Ä–≤—ñ—Å—É"""
    return {
        "status": "online",
        "gpu_available": GPU_AVAILABLE,
        "supported_formats": list(SUPPORTED_FORMATS),
        "max_file_size_mb": MAX_FILE_SIZE // (1024 * 1024)
    }


@app.post("/api/upload")
async def upload_audio(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    colormap: str = "magma",
    scale: str = "linear",
    fft_size: int = 2048,
    mode: str = "classic",
    use_gpu: bool = True
):
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ—Ñ–∞–π–ª—É –¥–ª—è –æ–±—Ä–æ–±–∫–∏
    """
    # –í–∞–ª—ñ–¥–∞—Ü—ñ—è
    if not validate_audio_file(file.filename):
        raise HTTPException(
            status_code=400,
            detail=f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç. –î–æ–∑–≤–æ–ª–µ–Ω—ñ: {', '.join(SUPPORTED_FORMATS)}"
        )

    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä–æ–∑–º—ñ—Ä—É
    file.file.seek(0, 2)
    file_size = file.file.tell()
    file.file.seek(0)

    if file_size > MAX_FILE_SIZE:
        raise HTTPException(
            status_code=400,
            detail=f"–§–∞–π–ª –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∏–π. –ú–∞–∫—Å–∏–º—É–º: {MAX_FILE_SIZE // (1024*1024)} MB"
        )

    # –í–∞–ª—ñ–¥–∞—Ü—ñ—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    if scale.lower() not in ["linear", "log", "mel"]:
        raise HTTPException(status_code=400, detail="–ú–∞—Å—à—Ç–∞–± –º–∞—î –±—É—Ç–∏ 'linear', 'log' –∞–±–æ 'mel'")

    if fft_size not in [1024, 2048, 4096, 8192, 16384]:
        raise HTTPException(status_code=400, detail="FFT Size –º–∞—î –±—É—Ç–∏ 1024, 2048, 4096, 8192 –∞–±–æ 16384")

    if mode not in ["classic", "sharp", "sharper"]:
        raise HTTPException(status_code=400, detail="Mode –º–∞—î –±—É—Ç–∏ 'classic', 'sharp' –∞–±–æ 'sharper'")

    # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è ID –∑–∞–≤–¥–∞–Ω–Ω—è (–Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ç–∞–π–º—Å—Ç–µ–º–ø—É)
    task_id = generate_task_id()

    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É
    file_ext = Path(file.filename).suffix
    original_stem = Path(file.filename).stem or "audio"
    temp_path = UPLOAD_DIR / f"{task_id}{file_ext}"

    with open(temp_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å—Ç–∞—Ç—É—Å—É
    tasks_status[task_id] = {
        "task_id": task_id,
        "status": "pending",
        "progress": 0,
        "message": "–ó–∞–≤–¥–∞–Ω–Ω—è —Å—Ç–≤–æ—Ä–µ–Ω–æ",
        "result": None
    }

    # –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ—ó –æ–±—Ä–æ–±–∫–∏
    background_tasks.add_task(
        process_audio_task,
        task_id,
        str(temp_path),
        original_stem,
        colormap,
        scale.lower(),
        fft_size,
        mode,
        use_gpu
    )

    return {"task_id": task_id, "message": "–§–∞–π–ª –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ, –æ–±—Ä–æ–±–∫–∞ —Ä–æ–∑–ø–æ—á–∞—Ç–∞"}


@app.post("/api/preview")
async def generate_preview(
    file: UploadFile = File(...),
    colormap: str = "magma",
    scale: str = "linear",
    fft_size: int = 2048,
    mode: str = "classic",
    use_gpu: bool = True
):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø—Ä–µ–≤ º—é —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏ (320px) –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —á–∞—Å—É
    """
    # –õ–æ–≥—É–≤–∞–Ω–Ω—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –ø—Ä–µ–≤ º—é: colormap={colormap}, scale={scale}, fft_size={fft_size}, mode={mode}")

    # –í–∞–ª—ñ–¥–∞—Ü—ñ—è
    if not validate_audio_file(file.filename):
        raise HTTPException(
            status_code=400,
            detail=f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç. –î–æ–∑–≤–æ–ª–µ–Ω—ñ: {', '.join(SUPPORTED_FORMATS)}"
        )

    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä–æ–∑–º—ñ—Ä—É
    file.file.seek(0, 2)
    file_size = file.file.tell()
    file.file.seek(0)

    if file_size > MAX_FILE_SIZE:
        raise HTTPException(
            status_code=400,
            detail=f"–§–∞–π–ª –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∏–π. –ú–∞–∫—Å–∏–º—É–º: {MAX_FILE_SIZE // (1024*1024)} MB"
        )

    # –í–∞–ª—ñ–¥–∞—Ü—ñ—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    if scale.lower() not in ["linear", "log", "mel"]:
        raise HTTPException(status_code=400, detail="–ú–∞—Å—à—Ç–∞–± –º–∞—î –±—É—Ç–∏ 'linear', 'log' –∞–±–æ 'mel'")

    if fft_size not in [1024, 2048, 4096, 8192, 16384]:
        raise HTTPException(status_code=400, detail="FFT Size –º–∞—î –±—É—Ç–∏ 1024, 2048, 4096, 8192 –∞–±–æ 16384")

    if mode not in ["classic", "sharp", "sharper"]:
        raise HTTPException(status_code=400, detail="Mode –º–∞—î –±—É—Ç–∏ 'classic', 'sharp' –∞–±–æ 'sharper'")

    try:
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ç–∏–º—á–∞—Å–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É
        temp_id = generate_task_id()
        temp_path = UPLOAD_DIR / f"{temp_id}{Path(file.filename).suffix}"

        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —É–Ω—ñ–∫–∞–ª—å–Ω–æ–≥–æ —ñ–º–µ–Ω—ñ —Ñ–∞–π–ª—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
        params_hash = generate_preview_hash(colormap, scale, fft_size, mode)
        preview_path = OUTPUT_DIR / f"{temp_id}_{params_hash}_preview{IMAGE_EXT}"

        with open(temp_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)

        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø—Ä–µ–≤ º—é
        info = generate_2d_preview(str(temp_path), str(preview_path), colormap, scale, fft_size, mode, use_gpu)

        # –û—á–∏—â–µ–Ω–Ω—è —Ç–∏–º—á–∞—Å–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É
        os.remove(temp_path)

        print(f"‚úì –ü—Ä–µ–≤ º—é –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ: {preview_path.name}")

        return {
            "preview_url": f"/outputs/{preview_path.name}",
            "filename": preview_path.name,
            **info
        }

    except Exception as e:
        print(f"‚úó –ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –ø—Ä–µ–≤ º—é: {str(e)}")
        raise HTTPException(status_code=500, detail=f"–ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –ø—Ä–µ–≤ º—é: {str(e)}")


@app.get("/api/task/{task_id}")
async def get_task_status(task_id: str):
    """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–∞—Ç—É—Å—É –∑–∞–≤–¥–∞–Ω–Ω—è"""
    if task_id not in tasks_status:
        raise HTTPException(status_code=404, detail="–ó–∞–≤–¥–∞–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
    return tasks_status[task_id]


@app.post("/api/download-4k")
async def download_4k_spectrogram(
    file: UploadFile = File(...),
    colormap: str = "magma",
    scale: str = "linear",
    fft_size: int = 2048,
    mode: str = "classic",
    use_gpu: bool = True
):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è 4K —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏ (3840x2160)
    """
    # –í–∞–ª—ñ–¥–∞—Ü—ñ—è
    if not validate_audio_file(file.filename):
        raise HTTPException(
            status_code=400,
            detail=f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç. –î–æ–∑–≤–æ–ª–µ–Ω—ñ: {', '.join(SUPPORTED_FORMATS)}"
        )

    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä–æ–∑–º—ñ—Ä—É
    file.file.seek(0, 2)
    file_size = file.file.tell()
    file.file.seek(0)

    if file_size > MAX_FILE_SIZE:
        raise HTTPException(
            status_code=400,
            detail=f"–§–∞–π–ª –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∏–π. –ú–∞–∫—Å–∏–º—É–º: {MAX_FILE_SIZE // (1024*1024)} MB"
        )

    # –í–∞–ª—ñ–¥–∞—Ü—ñ—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    if scale.lower() not in ["linear", "log", "mel"]:
        raise HTTPException(status_code=400, detail="–ú–∞—Å—à—Ç–∞–± –º–∞—î –±—É—Ç–∏ 'linear', 'log' –∞–±–æ 'mel'")

    if fft_size not in [1024, 2048, 4096, 8192, 16384]:
        raise HTTPException(status_code=400, detail="FFT Size –º–∞—î –±—É—Ç–∏ 1024, 2048, 4096, 8192 –∞–±–æ 16384")

    if mode not in ["classic", "sharp", "sharper"]:
        raise HTTPException(status_code=400, detail="Mode –º–∞—î –±—É—Ç–∏ 'classic', 'sharp' –∞–±–æ 'sharper'")

    try:
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ç–∏–º—á–∞—Å–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É
        temp_id = generate_task_id()
        temp_path = UPLOAD_DIR / f"{temp_id}{Path(file.filename).suffix}"
        output_path = OUTPUT_DIR / f"{temp_id}_4k{IMAGE_EXT}"

        with open(temp_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)

        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è 4K —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏
        generate_2d_spectrogram(str(temp_path), str(output_path), colormap, scale, fft_size, mode, use_gpu)

        # –û—á–∏—â–µ–Ω–Ω—è —Ç–∏–º—á–∞—Å–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É
        os.remove(temp_path)

        # –ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è —Ñ–∞–π–ª—É –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        media_type = "image/jpeg" if IMAGE_FORMAT == "jpeg" else "image/png"
        return FileResponse(
            path=str(output_path),
            filename=f"spectrogram_4k_{temp_id}{IMAGE_EXT}",
            media_type=media_type
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó 4K: {str(e)}")


@app.get("/api/download/{filename}")
async def download_file(filename: str):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É"""
    file_path = OUTPUT_DIR / filename
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="–§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")

    lower_name = filename.lower()
    if lower_name.endswith((".jpg", ".jpeg")):
        media_type = "image/jpeg"
    elif lower_name.endswith(".png"):
        media_type = "image/png"
    else:
        media_type = "application/octet-stream"
    return FileResponse(
        path=str(file_path),
        filename=filename,
        media_type=media_type
    )


@app.delete("/api/cleanup")
async def cleanup_old_files(max_age_hours: int = 24):
    """–û—á–∏—â–µ–Ω–Ω—è —Å—Ç–∞—Ä–∏—Ö —Ñ–∞–π–ª—ñ–≤"""
    cutoff = datetime.now() - timedelta(hours=max_age_hours)
    removed = 0

    for directory in [OUTPUT_DIR, UPLOAD_DIR]:
        for file in directory.iterdir():
            if file.is_file():
                mtime = datetime.fromtimestamp(file.stat().st_mtime)
                if mtime < cutoff:
                    file.unlink()
                    removed += 1

    return {"removed_files": removed}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
